{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPT07VxgR+RpSB5DQKDgWKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadMobasher/Binance-Prediction-LSTM/blob/main/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwEHw3a7lsYe"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-90RQyAlcAD"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime, pytz\n",
        "plt.style.use('fivethirtyeight') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsJhnJcTmBSX"
      },
      "source": [
        "# Import Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWSCYaxgmDb9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kLqd29Ulzwt"
      },
      "source": [
        "# Load data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mYuUG8tl4OV"
      },
      "source": [
        "#define a conversion function for the native timestamps in the csv file\n",
        "def dateparse (time_in_secs):    \n",
        "    return datetime.datetime.fromtimestamp(float(time_in_secs))\n",
        "\n",
        "# load the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/BTC-2010-2021.csv', delimiter=',', parse_dates=['time'], date_parser=dateparse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6IhCp4Gl_OG"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhRt34AqmOP_"
      },
      "source": [
        "# Preparing our data for feeding to model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnYyjGMCmPsV"
      },
      "source": [
        "cols = list(dataset)[1:5]\n",
        "df_for_training = dataset[cols].astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az23IS9AmUy3"
      },
      "source": [
        "scaler = RobustScaler()\n",
        "robust_df = scaler.fit(df_for_training)\n",
        "df_for_training_scaled = scaler.transform(df_for_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as1vZMBsmV9H"
      },
      "source": [
        "standardScaler = StandardScaler()\n",
        "standardScaler = standardScaler.fit(df_for_training)\n",
        "df_for_training_scaled = scaler.transform(df_for_training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkiDkom6mX1N"
      },
      "source": [
        "# Preparing data for network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_VT6k0emccf"
      },
      "source": [
        "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
        "#In this example, the n_features is 2. We will make timesteps = 3. \n",
        "#With this, the resultant n_samples is 5 (as the input data has 9 rows).\n",
        "trainX = []\n",
        "trainY = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCWbKXbLmfjf"
      },
      "source": [
        "n_future = 1   # Number of days we want to predict into the future\n",
        "n_past = 100     # Number of past days we want to use to predict the future\n",
        "\n",
        "for i in range(n_past, len(df_for_training_scaled) - n_future +1):\n",
        "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1] + 2])\n",
        "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0:4])\n",
        "\n",
        "trainX, trainY = np.array(trainX), np.array(trainY)\n",
        "\n",
        "print('trainX shape == {}.'.format(trainX.shape))\n",
        "print('trainY shape == {}.'.format(trainY.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_v-QgTAmiHF"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBvM3MPmjS3"
      },
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 100, return_sequences = True, input_shape = (trainX.shape[1], trainX.shape[2])))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 150, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "# , activation=tf.nn.relu\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 160, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 140, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 120, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(LSTM(units = 60, return_sequences = False))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "#=============================================================\n",
        "\n",
        "regressor.add(Dense(units = trainY.shape[2]))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "history = regressor.fit(trainX, trainY, epochs = 110, batch_size = 128, validation_split=0.1, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6hNwCvHmmdx"
      },
      "source": [
        "# Model History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONp3FF3LmqBg"
      },
      "source": [
        "plt.plot(history.history['loss'], label='Training loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R9x9piXmqkP"
      },
      "source": [
        "# Predict for 30 fay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fe2LQTCm0sX"
      },
      "source": [
        "predict_n_future = 30\n",
        "predicted_dataset = []\n",
        "for i in range(0, n_past):\n",
        "  predicted_dataset.append(trainX[trainX.shape[0] - 1][i])\n",
        "\n",
        "predicted_dataset.append(regressor.predict(np.array(predicted_dataset).reshape((1, n_past, trainX.shape[2])))[0])\n",
        "\n",
        "for i in range(1, predict_n_future):\n",
        "  predicted_dataset.append(regressor.predict(np.array(predicted_dataset[len(predicted_dataset) - n_past : ]).reshape(1, n_past, trainX.shape[2]))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMsBmxhPm13w"
      },
      "source": [
        "y_pred_future = scaler.inverse_transform(predicted_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mPplyVUm2yv"
      },
      "source": [
        "# Ploting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvD-rHDim4Tf"
      },
      "source": [
        "datelist_future = pd.date_range(dataset.iloc[-1]['time'], periods=predict_n_future, freq='1d').tolist()\n",
        "forecast_dates = []\n",
        "for time_i in datelist_future:\n",
        "    forecast_dates.append(time_i.date())\n",
        "    \n",
        "df_forecast = pd.DataFrame({'time':np.array(forecast_dates), 'open':y_pred_future[n_past:, 0]})\n",
        "df_forecast['time'] = pd.to_datetime(df_forecast['time'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOrPmjXKm5R_"
      },
      "source": [
        "original = dataset[['time', 'open']]\n",
        "original['time'] = pd.to_datetime(original['time'])\n",
        "# original['time'] = y_pred_train\n",
        "original = original.loc[original['time'] >= '2020-8-1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLPsgg2Pm6XP"
      },
      "source": [
        "forecast_period_dates1 = pd.date_range(dataset.iloc[n_past + 6]['time'], periods=y_pred_train.shape[0], freq='1d').tolist()\n",
        "forecast_dates1 = []\n",
        "for time_i in forecast_period_dates1:\n",
        "    forecast_dates1.append(time_i.date())\n",
        "    \n",
        "df_forecast1 = pd.DataFrame({'time':np.array(forecast_dates1), 'open':y_pred_train})\n",
        "df_forecast1['time'] = pd.to_datetime(df_forecast1['time'])\n",
        "df_forecast1 = df_forecast1.loc[df_forecast1['time'] >= '2020-8-1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INTJj2YGm7dP"
      },
      "source": [
        "sns.set(rc={'figure.figsize':(25,15)})\n",
        "sns.lineplot(original['time'], original['open'], label = 'original')\n",
        "sns.lineplot(df_forecast['time'], df_forecast['open'], label = 'future')\n",
        "sns.lineplot(df_forecast1['time'], df_forecast1[\"open\"], label = 'train')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}